{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait a moment \n",
      "FINISHED classifying. accuracy score : \n",
      "0.9814814814814815\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "root_dir=\"train-mails\"\n",
    "TEST_DIR='test-mails'\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('wait a moment ')\n",
    "def make_dictionary(root_dir):\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords=stopwords.words('english')\n",
    "    all_words=[]\n",
    "    emails=[os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "    for mails in emails:\n",
    "        with open(mails) as m:\n",
    "            for line in m:\n",
    "                words=line.split()\n",
    "                words =[a for a in words if a.isalpha() if a not in stopwords if not len(a)==1 ]\n",
    "                all_words+=words\n",
    "    dictionary =Counter(all_words)\n",
    "    dictionary=dictionary.most_common(3000)\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def extract_features(root_dir):\n",
    "    import numpy as np\n",
    "    root_dir=\"train-mails\"\n",
    "    emails=[os.path.join(root_dir,fi) for fi in os.listdir(root_dir)]\n",
    "    features_matrix=np.zeros((len(emails),3000))\n",
    "    train_labels=np.zeros(len(emails))\n",
    "    docid=0\n",
    "    count=0\n",
    "    wordid=0\n",
    "\n",
    "    for file in emails:\n",
    "        with open(file) as m:\n",
    "            for i ,line in enumerate(m):\n",
    "                if i==2:\n",
    "                    words=line.split()\n",
    "                    for word in words:\n",
    "    #                     print('hii')\n",
    "                        wordid=0\n",
    "                        for i , d in enumerate(dictionary):\n",
    "                            if d[0]==word:\n",
    "                                wordid=i\n",
    "                                features_matrix[docid,wordid]=words.count(word)\n",
    "    #                             print(words.count(word))\n",
    "            train_labels[docid]=0\n",
    "            filepathTokens=file.split('/')\n",
    "            last_token=filepathTokens[len(filepathTokens)-1]\n",
    "            if 'spmsg' in last_token:\n",
    "                count+=1\n",
    "                train_labels[docid]=1\n",
    "            docid+=1\n",
    "    return features_matrix,train_labels\n",
    "\n",
    "dictionary=make_dictionary(root_dir)\n",
    "features_matrix, labels = extract_features(root_dir)\n",
    "test_feature_matrix, test_labels = extract_features(TEST_DIR)\n",
    "model = GaussianNB()\n",
    "model.fit(features_matrix, labels)\n",
    "predicted_labels = model.predict(test_feature_matrix)\n",
    "print(\"FINISHED classifying. accuracy score : \")\n",
    "print(accuracy_score(test_labels, predicted_labels))\n",
    "print('done')\n",
    "# print(predicted_labels)\n",
    "# test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
